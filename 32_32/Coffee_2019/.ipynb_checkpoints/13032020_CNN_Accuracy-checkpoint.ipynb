{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Add, Input, Multiply, Concatenate, GlobalAveragePooling2D\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "import os, glob, random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "num_classes = 2\n",
    "#epochs = 50\n",
    "epochs = 50\n",
    "#data_augmentation = False\n",
    "#num_predictions = 20\n",
    "#save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_path = 'C:/Users/Hira/Desktop/Coffee Bean Size_05032020/32_32/Coffee_2019/mbnv2_model_5.h5'\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "train_dir = 'C:/Users/Hira/Desktop/Coffee Bean Size_05032020/32_32/Coffee_2019/Train/'\n",
    "validation_dir = 'C:/Users/Hira/Desktop/Coffee Bean Size_05032020/32_32/Coffee_2019/Validation/'\n",
    "\n",
    "class_label = ['OK', 'NG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hira\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "#input_tensorの定義\n",
    "input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "#Create the base model from the pre-trained convnets\n",
    "model = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "top_model = Sequential()\n",
    "#top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D())  #Global Average Pooling 層の良いポイント,パラメーター数を非常に少なくすることができる→　モデルが単純になり、過学習をしにくくなる\n",
    "top_model.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# mobilenetv2とtop_modelを連結\n",
    "model = Model(inputs=model.input, outputs=top_model(model.output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#img_width, img_height = 128, 128\n",
    "nb_train_samples = 2670 \n",
    "nb_validation_samples = 334 \n",
    "epochs = 50\n",
    "batch_size = 11\n",
    "nb_category = 2\n",
    "\n",
    "callbacks = list()\n",
    "callbacks.append(ModelCheckpoint(filepath=\"C:/Users/Hira/Desktop/Coffee Bean Size_05032020/32_32/Coffee_2019/mbnv2_model_5.h5\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(lr=0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "check_point = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = os.path.join('mbnv2_model{epoch:02d}-vacc{val_acc:.2f}.hdf5'), \n",
    "        monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "    \n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    #horizontal_flip=True\n",
    ")\n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    #shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    #shuffle=True\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=25,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        #callbacks=[check_point]\n",
    "        callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save(model_path)\n",
    "print('\\nSaved trained model at --> %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam\n",
    "#for test\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os,random\n",
    "from keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss (Cross Entropy)')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam\n",
    "#for test\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os,random\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "print(\"Wainting...\")\n",
    "#img_width, img_height = 128,128\n",
    "nb_test_samples = 334\n",
    "#batch_size = 1\n",
    "nb_category = 2\n",
    "\n",
    "batch_size=11\n",
    "#file_name='vgg16_been_224'\n",
    "test_dir='C:/Users/Hira/Desktop/Coffee Bean Size_05032020/32_32/Coffee_2019/Test/'\n",
    "#display_dir='/home/reeen/Documents/keras/cnn3display'\n",
    "label=['OK','NG']\n",
    "\n",
    "print(\"Wainting...\")\n",
    "\n",
    "#load model and weights\n",
    "#json_string=open(file_name+'.json').read()\n",
    "#model=model_from_json(json_string)\n",
    "model.load_weights(model_path)\n",
    "#model.load_weights('/home/reeen/Documents/keras/cnn5/models/vgg16_weight_epoch978.h5')\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#data generate\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    #shuffle=True\n",
    ")\n",
    "\n",
    "#evaluate model\n",
    "score=model.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps=nb_test_samples,\n",
    "     verbose=1)\n",
    "print('\\n test loss:',score[0])\n",
    "print('\\n test_acc:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
